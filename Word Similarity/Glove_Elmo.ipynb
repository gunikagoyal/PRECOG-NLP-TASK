{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gunikagoyal/PRECOG-NLP-TASK/blob/main/Word%20Similarity/Glove_Elmo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GloVe word embeddings**"
      ],
      "metadata": {
        "id": "Ecr3zyWMpGFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load GloVe word embeddings\n",
        "glove_embeddings_path = \"/content/glove.6B.200d.txt\"\n",
        "word_embeddings = {}\n",
        "with open(glove_embeddings_path, 'r', encoding='utf-8') as file:\n",
        "    for line in tqdm(file):\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.array(values[1:], dtype='float32')\n",
        "        word_embeddings[word] = vector\n",
        "\n",
        "# Load word similarity dataset\n",
        "test_data_path = \"/content/SimLex-999.txt\"\n",
        "test_data = pd.read_csv(test_data_path, sep='\\t')\n",
        "\n",
        "# Predict similarity scores using GloVe embeddings\n",
        "predicted_scores = []\n",
        "for idx, row in test_data.iterrows():\n",
        "    word1 = row['word1']\n",
        "    word2 = row['word2']\n",
        "\n",
        "    if word1 in word_embeddings and word2 in word_embeddings:\n",
        "        similarity_score = cosine_similarity([word_embeddings[word1]], [word_embeddings[word2]])[0][0]\n",
        "    else:\n",
        "        similarity_score = 0  # Default similarity\n",
        "\n",
        "    predicted_scores.append(similarity_score)\n",
        "\n",
        "# Evaluate using Spearman's rank correlation coefficient\n",
        "true_scores = test_data['SimLex999'].values\n",
        "correlation = pd.Series(predicted_scores).corr(pd.Series(true_scores), method='spearman')\n",
        "\n",
        "print(\"Spearman's Rank Correlation Coefficient using GloVe embeddings:\", correlation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blLYmxOGnEPj",
        "outputId": "1ecda94f-058f-4a44-9280-64bd99f0d3f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "208412it [00:17, 11812.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spearman's Rank Correlation Coefficient using GloVe embeddings: 0.34025352961510563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Elmo model**"
      ],
      "metadata": {
        "id": "vXzT4MjYpQPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load ELMo model\n",
        "elmo = hub.load(\"https://tfhub.dev/google/elmo/3\")\n",
        "\n",
        "# Load word similarity dataset\n",
        "test_data_path = \"/content/SimLex-999.txt\"\n",
        "test_data = pd.read_csv(test_data_path, sep='\\t')\n",
        "\n",
        "# Function to obtain ELMo embeddings for a sentence\n",
        "def elmo_embeddings(sentences):\n",
        "    embeddings = elmo.signatures[\"default\"](tf.convert_to_tensor(sentences))[\"elmo\"]\n",
        "    return embeddings.numpy()\n",
        "\n",
        "# Tokenize sentences and obtain ELMo embeddings\n",
        "elmo_embeddings_list = []\n",
        "for _, row in test_data.iterrows():\n",
        "    word1 = row['word1']\n",
        "    word2 = row['word2']\n",
        "\n",
        "    # Convert word pairs to sentences\n",
        "    sentence1 = word1 + ' .'\n",
        "    sentence2 = word2 + ' .'\n",
        "\n",
        "    # Obtain ELMo embeddings for the sentences\n",
        "    embeddings = elmo_embeddings([sentence1, sentence2])\n",
        "    embedding1 = embeddings[0].reshape(1, -1)\n",
        "    embedding2 = embeddings[1].reshape(1, -1)\n",
        "\n",
        "    # Compute cosine similarity between ELMo embeddings\n",
        "    similarity_score = cosine_similarity(embedding1, embedding2)[0][0]\n",
        "    elmo_embeddings_list.append(similarity_score)\n",
        "\n",
        "# Evaluate using Spearman's rank correlation coefficient\n",
        "true_scores = test_data['SimLex999'].values\n",
        "correlation = pd.Series(elmo_embeddings_list).corr(pd.Series(true_scores), method='spearman')\n",
        "\n",
        "print(\"Spearman's Rank Correlation Coefficient using ELMo embeddings:\", correlation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zO-1ESGzN8vA",
        "outputId": "8aeef544-113c-4b32-bb5c-1ee25443f5eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spearman's Rank Correlation Coefficient using ELMo embeddings: 0.43267354384569995\n"
          ]
        }
      ]
    }
  ]
}